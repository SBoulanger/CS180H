{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numeric_columns = [\n",
    " 'requester_account_age_in_days_at_request',\n",
    " 'requester_days_since_first_post_on_raop_at_request',\n",
    " 'requester_number_of_comments_at_request',\n",
    " 'requester_number_of_comments_in_raop_at_request',\n",
    " 'requester_number_of_posts_at_request',\n",
    " 'requester_number_of_posts_on_raop_at_request',\n",
    " 'requester_number_of_subreddits_at_request',\n",
    " 'requester_upvotes_minus_downvotes_at_request',\n",
    " 'requester_upvotes_plus_downvotes_at_request',\n",
    " 'unix_timestamp_of_request',\n",
    " 'unix_timestamp_of_request_utc',\n",
    " 'requester_received_pizza']\n",
    "\n",
    "def read_data(mode):\n",
    "    # WARNING: THIS FUNCTION IS DROPPING SPARSE COLUMNS\n",
    "#     dataframe = pd.DataFrame()\n",
    "#     dataframe.columns=numeric_columns\n",
    "    if mode == 'train':\n",
    "        dataframe = pd.read_json('./data/train.json')\n",
    "        dataframe['requester_received_pizza'] = dataframe['requester_received_pizza'].astype(int)\n",
    "    elif mode == 'test':\n",
    "        dataframe = pd.read_json('./data/test.json')\n",
    "        \n",
    "    return dataframe\n",
    "    \n",
    "\n",
    "# def x_y_split(dataframe):\n",
    "#     \"\"\" Splits a pd dataframe into the features and results \"\"\"\n",
    "#     features = dataframe.drop('requester_received_pizza', axis=1)\n",
    "#     results = dataframe['requester_received_pizza']\n",
    "#     return features, results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = read_data('train')\n",
    "train_df[numeric_columns].to_csv('./data/train.csv', index=False)\n",
    "# test_df = read_data('test')\n",
    "# test_df[numeric_columns[:-1]].to_csv('./data/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df[numeric_columns].to_csv('./data/train.csv')\n",
    "#list(train_df.columns.intersection(test_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(pd.read_csv('./data/train.csv').columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'Const:0' shape=(0,) dtype=float32>,\n",
       " <tf.Tensor 'Const_1:0' shape=(0,) dtype=float32>,\n",
       " <tf.Tensor 'Const_2:0' shape=(0,) dtype=float32>,\n",
       " <tf.Tensor 'Const_3:0' shape=(0,) dtype=float32>,\n",
       " <tf.Tensor 'Const_4:0' shape=(0,) dtype=float32>,\n",
       " <tf.Tensor 'Const_5:0' shape=(0,) dtype=float32>,\n",
       " <tf.Tensor 'Const_6:0' shape=(0,) dtype=float32>,\n",
       " <tf.Tensor 'Const_7:0' shape=(0,) dtype=float32>,\n",
       " <tf.Tensor 'Const_8:0' shape=(0,) dtype=float32>,\n",
       " <tf.Tensor 'Const_9:0' shape=(0,) dtype=float32>,\n",
       " <tf.Tensor 'Const_10:0' shape=(0,) dtype=float32>,\n",
       " <tf.Tensor 'Const_11:0' shape=(0,) dtype=float32>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_defaults = [tf.constant([], dtype=tf.float32) for c in range(len(numeric_columns))]\n",
    "record_defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(data_file, num_epochs, shuffle, batch_size):\n",
    "    \"\"\" Generate an input function for the Estimator \"\"\"\n",
    "    assert tf.gfile.Exists(data_file), (f'{data_file} not found. Please make sure the data file is in the correct location.')\n",
    "    \n",
    "    def parse_csv(value):\n",
    "        print('Parsing', data_file)\n",
    "        columns = tf.decode_csv(value, record_defaults=record_defaults)\n",
    "        features = dict(zip(numeric_columns, columns))\n",
    "        labels = features.pop('requester_received_pizza')\n",
    "        return features, labels\n",
    "    \n",
    "    dataset = tf.contrib.data.TextLineDataset(data_file) # in TF 1.4 data got moved to tf.contrib: https://github.com/tensorflow/tensorflow/releases/tag/v1.4.0\n",
    "    \n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=10)\n",
    "        \n",
    "    dataset = dataset.map(parse_csv, num_threads=5)\n",
    "    \n",
    "    dataset = dataset.repeat(num_epochs)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    \n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    features, labels = iterator.get_next()\n",
    "    return features, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical columns\n",
    "# post_was_edited true or false\n",
    "# requester_received_pizza true or fasle\n",
    "# requester_user_flair None, \"schroom\", \"PIF\"\n",
    "# everything else numerical\n",
    "\n",
    "tf_feature_columns = [tf.feature_column.numeric_column(x) for x in numeric_columns[:-1]]\n",
    "# tensorflow features cannot accept strings. must transform strings to categorical or numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './models/', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100}\n"
     ]
    }
   ],
   "source": [
    "model_dir = './models/'\n",
    "model = tf.estimator.LinearClassifier(\n",
    "    model_dir=model_dir, \n",
    "    feature_columns=tf_feature_columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing ./data/train.csv\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./models/model.ckpt.\n",
      "INFO:tensorflow:loss = 20.7944, step = 1\n",
      "INFO:tensorflow:global_step/sec: 614.743\n",
      "INFO:tensorflow:loss = 3.6438e+08, step = 101 (0.163 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 135 into ./models/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.02013e+08.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.linear.LinearClassifier at 0x7f9c363b92e8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = './data/train.csv'\n",
    "num_epochs = 1\n",
    "shuffle = True\n",
    "batch_size = 30\n",
    "model.train(input_fn=lambda: input_fn(train_data, num_epochs, True, batch_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
